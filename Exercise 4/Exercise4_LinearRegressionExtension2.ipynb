{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Polynomial Regression\n",
    "\n",
    "### A) Use the Auto dataset, find the test $R^2$ score of a linear regression model that predicts the miles per gallon (mpg) from the horsepower.\n",
    "\n",
    "### B) Use polynomial regression to include both the horsepower feature and $(horsepower)^2$ in the regression model. Find the $R^2$ metric. \n",
    "\n",
    "Hint: You can use [numpy.concatenate](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html). For example to add to an array U a column vector $W^2$, we can use X=np.concatenate((U,W**2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square value is 0.6217658811398383\n",
      "The beta0 is 39.998611679300524\n",
      "The beta1 is -0.159527734327999\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "AutoData = read_csv('Auto_modify.csv') # read the data\n",
    "X = AutoData[['horsepower']]\n",
    "Y = AutoData['mpg']\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train,Y_train)\n",
    "Y_predict = linreg.predict(X_test)\n",
    "R_2 = r2_score(Y_test,Y_predict)\n",
    "print('R square value is',R_2)\n",
    "print('The beta0 is',linreg.intercept_)\n",
    "print('The beta1 is',np.array(linreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square value is 0.7271031504642005\n",
      "The beta0 is 39.998611679300524\n",
      "The beta1 is -0.4531023308533184\n",
      "The beta2 is 0.0011800690487566512\n"
     ]
    }
   ],
   "source": [
    "AutoData['horsepower^2'] = pow(AutoData['horsepower'],2)\n",
    "X1 = AutoData[['horsepower','horsepower^2']]\n",
    "X_train1,X_test1,Y_train1,Y_test1 = train_test_split(X1,Y,random_state = 0)\n",
    "linreg1 = LinearRegression().fit(X_train1,Y_train1)\n",
    "R_2 = r2_score(Y_test,linreg1.predict(X_test1))\n",
    "print('R square value is',R_2)\n",
    "print('The beta0 is',linreg.intercept_)\n",
    "print('The beta1 is',np.array(linreg1.coef_[0]))\n",
    "print('The beta2 is',np.array(linreg1.coef_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)Use KNN regression to predict the miles per gallon(mpg) with K=7, and find $R^2$ metric in the following cases \n",
    "\n",
    "- One feature: Horsepower only\n",
    "\n",
    "- Two features: horsepower and $(horsepower)^2$ \n",
    "\n",
    "Hint: \n",
    "\n",
    "    Create KNN regression object using neighbors.KNeighborsRegressor:\n",
    "\n",
    "    knnRegression = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "\n",
    "    Use the .fit and .score methods as before\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square value is 0.6674777441714226\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knnRegression = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
    "Knn_reg1 = knnRegression.fit(X_train,Y_train)\n",
    "Y_predict = Knn_reg1.predict(X_test)\n",
    "R_2 = r2_score(Y_test,Y_predict)\n",
    "print('R square value is',R_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square value is 0.6701084048823853\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knnRegression = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
    "Knn_reg2 = knnRegression.fit(X_train1,Y_train1)\n",
    "Y_predict = Knn_reg2.predict(X_test1)\n",
    "R_2 = r2_score(Y_test,Y_predict)\n",
    "print('R square value is',R_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMMENT on your results on (E) and (F): which model performs better? How does performance change when adding the quadratic feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2: Regularization\n",
    "\n",
    "### A) Use the Boston dataset, and use Ridge regression model with tuning parameter set to 100 (alpha =100). Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "###  B) Use Lasso regression instead of Ridge regression, also set the tuning parameter to 100. Find the $R^2$ score and number of non zero coefficients.\n",
    "\n",
    "### C) Change the tuning parameter of the Lasso model to a very low value (alpha =0.001). What is the $R^2$ score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_boston()\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for Ridge Regression w/ tuning parameter of 100: 0.5925358036157629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.10593087,  0.05388664, -0.06777195,  0.48192973, -0.16346727,\n",
       "        1.98200812, -0.00433025, -1.15460301,  0.24416784, -0.01437486,\n",
       "       -0.87957246,  0.00845672, -0.64846291])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A\n",
    "RidgeModel = Ridge(alpha = 100).fit(X_train,Y_train)\n",
    "R2_1 = r2_score(Y_test,RidgeModel.predict(X_test))\n",
    "print('R^2 for Ridge Regression w/ tuning parameter of 100:', R2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for Ridge Regression w/ tuning parameter of 100: 0.11866916175527809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.02291247,\n",
       "       -0.        ,  0.00482211, -0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B\n",
    "LassoModel1 = Lasso(alpha = 100).fit(X_train,Y_train)\n",
    "R2_2 = r2_score(Y_test,LassoModel1.predict(X_test))\n",
    "print('R^2 for Ridge Regression w/ tuning parameter of 100:', R2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for Ridge Regression w/ tuning parameter of 0.001: 0.6350353125168686\n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "LassoModel2 = Lasso(alpha = 0.001).fit(X_train,Y_train)\n",
    "R2_3 = r2_score(Y_test,LassoModel2.predict(X_test))\n",
    "print('R^2 for Ridge Regression w/ tuning parameter of 0.001:', R2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### D) Comment on your result. In this problem, do all feature seem important in making predictions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All features are important in terms of making prediction. In (B) we could see R_2 value drops dramatically as we forced all parameters, beta's, to be zero as implementing a large tuning parameter. Once we chose a smaller tuning parameter in (C), all features are took in account and R_2 suddenly improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
